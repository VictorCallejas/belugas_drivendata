{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLAB\n",
    "!pip install neptune-client timm\n",
    "# pip install torch-tensorrt -f https://github.com/NVIDIA/Torch-TensorRT/releases\n",
    "!unzip data.zip\n",
    "!mkdir artifacts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "from torch import einsum\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torchvision \n",
    "from torchvision import transforms as T\n",
    "from torchvision.io import read_image\n",
    "\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import neptune.new as neptune\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/victorcallejas/Belluga/e/BEL-131\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init(\n",
    "    project=\"victorcallejas/Belluga\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlNDRlNTJiNC00OTQwLTQxYjgtYWZiNS02OWQ0MDcwZmU5N2YifQ==\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 1070 with Max-Q Design _CudaDeviceProperties(name='NVIDIA GeForce GTX 1070 with Max-Q Design', major=6, minor=1, total_memory=8191MB, multi_processor_count=16)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "print(torch.cuda.get_device_name(0), torch.cuda.get_device_properties(device))\n",
    "\n",
    "fp16 = True\n",
    "input_dtype = torch.float16 if fp16 else torch.float32\n",
    "\n",
    "scaler =  torch.cuda.amp.GradScaler(enabled=fp16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCORING\n",
    "PREDICTION_LIMIT = 20\n",
    "QUERY_ID_COL = \"query_id\"\n",
    "DATABASE_ID_COL = \"database_image_id\"\n",
    "SCORE_COL = \"score\"\n",
    "\n",
    "SCORE_THRESHOLD = 0.5\n",
    "\n",
    "class MeanAveragePrecision:\n",
    "    @classmethod\n",
    "    def score(cls, predicted: pd.DataFrame, actual: pd.DataFrame, prediction_limit: int):\n",
    "        \"\"\"Calculates mean average precision for a ranking task.\n",
    "        :param predicted: The predicted values as a dataframe with specified column names\n",
    "        :param actual: The ground truth values as a dataframe with specified column names\n",
    "        \"\"\"\n",
    "        if not predicted[SCORE_COL].between(0.0, 1.0).all():\n",
    "            raise ValueError(\"Scores must be in range [0, 1].\")\n",
    "        if predicted.index.name != QUERY_ID_COL:\n",
    "            raise ValueError(\n",
    "                f\"First column of submission must be named '{QUERY_ID_COL}', \"\n",
    "                f\"got {predicted.index.name}.\"\n",
    "            )\n",
    "        if predicted.columns.to_list() != [DATABASE_ID_COL, SCORE_COL]:\n",
    "            raise ValueError(\n",
    "                f\"Columns of submission must be named '{[DATABASE_ID_COL, SCORE_COL]}', \"\n",
    "                f\"got {predicted.columns.to_list()}.\"\n",
    "            )\n",
    "\n",
    "        unadjusted_aps, predicted_n_pos, actual_n_pos = cls._score_per_query(\n",
    "            predicted, actual, prediction_limit\n",
    "        )\n",
    "        adjusted_aps = unadjusted_aps.multiply(predicted_n_pos).divide(actual_n_pos)\n",
    "        return adjusted_aps.mean()\n",
    "\n",
    "    @classmethod\n",
    "    def _score_per_query(\n",
    "        cls, predicted: pd.DataFrame, actual: pd.DataFrame, prediction_limit: int\n",
    "    ):\n",
    "        \"\"\"Calculates per-query mean average precision for a ranking task.\"\"\"\n",
    "        merged = predicted.merge(\n",
    "            right=actual.assign(actual=1.0),\n",
    "            how=\"left\",\n",
    "            on=[QUERY_ID_COL, DATABASE_ID_COL],\n",
    "        ).fillna({\"actual\": 0.0})\n",
    "        # Per-query raw average precisions based on predictions\n",
    "        unadjusted_aps = merged.groupby(QUERY_ID_COL).apply(\n",
    "            lambda df: average_precision_score(df[\"actual\"].values, df[SCORE_COL].values)\n",
    "            if df[\"actual\"].sum()\n",
    "            else 0.0\n",
    "        )\n",
    "        # Total ground truth positive counts for rescaling\n",
    "        predicted_n_pos = merged[\"actual\"].groupby(QUERY_ID_COL).sum().astype(\"int64\").rename()\n",
    "        actual_n_pos = actual.groupby(QUERY_ID_COL).size().clip(upper=prediction_limit)\n",
    "        return unadjusted_aps, predicted_n_pos, actual_n_pos\n",
    "    \n",
    "    \n",
    "def map_score(dataloader, model, threshold=SCORE_THRESHOLD):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    sub = []\n",
    "    \n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    with torch.no_grad():        \n",
    "    \n",
    "        for query, reference, query_id, reference_id in tqdm(dataloader):\n",
    "            \n",
    "            query = query.to(device, non_blocking=True, dtype=input_dtype)\n",
    "            reference = reference.to(device, non_blocking=True, dtype=input_dtype)\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled = fp16):\n",
    "                logits = sigmoid(model(query=query, reference=reference)).cpu().squeeze().tolist()\n",
    "                \n",
    "            sub.extend(zip(query_id, reference_id, logits))\n",
    "            \n",
    "    sub = pd.DataFrame(sub, columns=['query_id', 'database_image_id', 'score'])\n",
    "    sub = sub[sub.score > threshold]\n",
    "    sub = sub.set_index(['database_image_id']).groupby('query_id')['score'].nlargest(20).reset_index()\n",
    "    sub = sub.set_index('query_id')\n",
    "    \n",
    "    mean_avg_prec = MeanAveragePrecision.score(\n",
    "        predicted=sub, actual=dataloader.dataset.gt, prediction_limit=PREDICTION_LIMIT\n",
    "    )\n",
    "    \n",
    "    print('MaP: ',mean_avg_prec)\n",
    "    return mean_avg_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5434/5434 [01:50<00:00, 49.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# DATA\n",
    "\n",
    "IMG_SIZE = 224\n",
    "ROOT_DIR = '../data/'\n",
    "NORM_TRANSFORMS = torch.nn.Sequential(\n",
    "    T.Resize([IMG_SIZE, IMG_SIZE]),\n",
    "    T.ConvertImageDtype(input_dtype),\n",
    "    T.Normalize(mean = (0.4234, 0.4272, 0.4641),\n",
    "                std  = (0.2037, 0.2027, 0.2142)),\n",
    ")\n",
    "\n",
    "VAL_SPLIT = 0.05\n",
    "\n",
    "METADATA = pd.read_csv('../data/metadata.csv')\n",
    "METADATA = METADATA[METADATA.viewpoint == 'top']\n",
    "\n",
    "TRAIN, VAL = train_test_split(METADATA, test_size=0.05, random_state=42)\n",
    "TRAIN, VAL = TRAIN.reset_index(), VAL.reset_index()\n",
    "#TRAIN, VAL = METADATA, METADATA\n",
    "#TRAIN = METADATA\n",
    "\n",
    "def getImages(metadata):\n",
    "    IMAGES = {}\n",
    "    for image_id, path in tqdm(zip(metadata.image_id, metadata.path), total=metadata.shape[0]):\n",
    "        IMAGES[image_id] = NORM_TRANSFORMS(read_image(ROOT_DIR + path))\n",
    "    return IMAGES\n",
    "\n",
    "IMAGES = getImages(METADATA)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreTrain_BellugaDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, metadata):\n",
    "        self.metadata = metadata\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.metadata.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return IMAGES[self.metadata.image_id[idx]]\n",
    "\n",
    "\n",
    "class Eval_BellugaDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, metadata):\n",
    "        self.metadata = metadata\n",
    "    \n",
    "        # GROUND TRUTH\n",
    "        gt = []\n",
    "        for wid in self.metadata.whale_id: # query\n",
    "            tmp = self.metadata[self.metadata.whale_id == wid].image_id.tolist() # get all images id\n",
    "            gt.extend(list(itertools.permutations(tmp, 2)))\n",
    "        self.gt = pd.DataFrame(gt,columns=['query_id','database_image_id'])\n",
    "        self.gt = self.gt.set_index('query_id')\n",
    "        \n",
    "        # ALL QUERIES\n",
    "        self.query_reference = list(itertools.permutations(self.metadata.image_id, 2))\n",
    "            \n",
    "    def getimage(self, image_id):\n",
    "        return IMAGES[image_id]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.query_reference)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        query_id = self.query_reference[idx][0]\n",
    "        reference_id = self.query_reference[idx][1]\n",
    "        \n",
    "        query = self.getimage(query_id)\n",
    "        reference = self.getimage(reference_id)\n",
    "        \n",
    "        return query, reference, query_id, reference_id\n",
    "    \n",
    "    \n",
    "class Train_BellugaDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, metadata):\n",
    "        self.metadata = metadata\n",
    "        #self.aug = T.RandomErasing(p=0.8, scale=(0.12, 0.43), ratio=(0.3, 3.3), value=0, inplace=False)\n",
    "            \n",
    "    def getimage(self, image_id):\n",
    "        return IMAGES[image_id]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.metadata.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        anchor = self.getimage(self.metadata.image_id[idx])\n",
    "        label = self.metadata.whale_id[idx]\n",
    "        \n",
    "        pos = self.getimage(self.metadata[self.metadata.whale_id == label].sample()['image_id'].values[0])\n",
    "        neg = self.getimage(self.metadata[self.metadata.whale_id != label].sample()['image_id'].values[0])\n",
    "\n",
    "        return anchor, pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATALOADERS \n",
    "\n",
    "PRETRAIN_BS = 4\n",
    "TRAIN_BS = 16\n",
    "INFER_BS = TRAIN_BS\n",
    "\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "\n",
    "#pretrain_dataset = PreTrain_BellugaDataset(METADATA)\n",
    "train_train_dataset = Train_BellugaDataset(TRAIN)\n",
    "#train_eval_dataset = Eval_BellugaDataset(TRAIN)\n",
    "valid_eval_dataset = Eval_BellugaDataset(VAL)\n",
    "\n",
    "'''\n",
    "pretrain_dataloader = torch.utils.data.DataLoader(\n",
    "                        pretrain_dataset, \n",
    "                        batch_size=PRETRAIN_BS,\n",
    "                        shuffle=True, \n",
    "                        num_workers=NUM_WORKERS,\n",
    "                        pin_memory=True\n",
    "                    )\n",
    "'''\n",
    "train_train_dataloader = torch.utils.data.DataLoader(\n",
    "                        train_train_dataset, \n",
    "                        batch_size=TRAIN_BS,\n",
    "                        shuffle=True, \n",
    "                        num_workers=NUM_WORKERS,\n",
    "                        pin_memory=True\n",
    "                    )\n",
    "'''\n",
    "train_eval_dataloader = torch.utils.data.DataLoader(\n",
    "                        train_eval_dataset, \n",
    "                        batch_size=INFER_BS,\n",
    "                        shuffle=True, \n",
    "                        num_workers=NUM_WORKERS,\n",
    "                        pin_memory=True\n",
    "                    )\n",
    "'''\n",
    "valid_eval_dataloader = torch.utils.data.DataLoader(\n",
    "                        valid_eval_dataset, \n",
    "                        batch_size=INFER_BS,\n",
    "                        shuffle=False, \n",
    "                        num_workers=NUM_WORKERS,\n",
    "                        pin_memory=True\n",
    "                    )   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "\n",
    "class CrossCNV(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = resnet18()\n",
    "        self.backbone.conv1 = nn.Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.backbone.fc = nn.Linear(in_features=512, out_features=1, bias=True)\n",
    "\n",
    "    def forward(self, query, reference):\n",
    "        x = torch.cat([query, reference], dim=1)\n",
    "        x = self.backbone(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "def crosscnv_base_224():\n",
    "    return CrossCNV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CrossCNV().to(device)\n",
    "\n",
    "#ckpt = torch.load('net_170.pt')\n",
    "#model.load_state_dict(ckpt['model_state_dict'], strict=False)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 5e-4)\n",
    "#optimizer.load_state_dict(ckpt['optimizer_state_dict'], )\n",
    "\n",
    "#opt = torch.optim.SGD(model.parameters(), lr = .05)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossCNV(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [01:25<00:00,  3.77it/s]\n",
      "100%|██████████| 4607/4607 [03:18<00:00, 23.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaP:  0.07933004577343532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [01:41<00:00,  3.18it/s]\n",
      "100%|██████████| 323/323 [01:41<00:00,  3.17it/s]\n",
      "100%|██████████| 323/323 [01:39<00:00,  3.26it/s]\n",
      "100%|██████████| 323/323 [01:42<00:00,  3.14it/s]\n",
      "100%|██████████| 323/323 [01:51<00:00,  2.89it/s]\n",
      "100%|██████████| 323/323 [01:35<00:00,  3.38it/s]\n",
      "100%|██████████| 323/323 [01:37<00:00,  3.33it/s]\n",
      "100%|██████████| 323/323 [01:42<00:00,  3.15it/s]\n",
      "100%|██████████| 323/323 [01:37<00:00,  3.33it/s]\n",
      "100%|██████████| 323/323 [01:35<00:00,  3.38it/s]\n",
      "100%|██████████| 4607/4607 [03:47<00:00, 20.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaP:  0.19133828358084343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [01:45<00:00,  3.07it/s]\n",
      "100%|██████████| 323/323 [01:51<00:00,  2.91it/s]\n",
      "100%|██████████| 323/323 [01:45<00:00,  3.06it/s]\n",
      "100%|██████████| 323/323 [01:37<00:00,  3.31it/s]\n",
      "100%|██████████| 323/323 [01:34<00:00,  3.40it/s]\n",
      "100%|██████████| 323/323 [01:33<00:00,  3.47it/s]\n",
      "100%|██████████| 323/323 [01:36<00:00,  3.35it/s]\n",
      "100%|██████████| 323/323 [01:46<00:00,  3.03it/s]\n",
      "100%|██████████| 323/323 [01:50<00:00,  2.91it/s]\n",
      "100%|██████████| 323/323 [01:57<00:00,  2.76it/s]\n",
      "100%|██████████| 4607/4607 [04:11<00:00, 18.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaP:  0.23659157446851564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [01:58<00:00,  2.73it/s]\n",
      "100%|██████████| 323/323 [01:46<00:00,  3.04it/s]\n",
      "100%|██████████| 323/323 [01:54<00:00,  2.83it/s]\n",
      "100%|██████████| 323/323 [01:47<00:00,  3.01it/s]\n",
      "100%|██████████| 323/323 [01:48<00:00,  2.99it/s]\n",
      "100%|██████████| 323/323 [01:45<00:00,  3.08it/s]\n",
      "100%|██████████| 323/323 [01:40<00:00,  3.22it/s]\n",
      "100%|██████████| 323/323 [01:35<00:00,  3.38it/s]\n",
      "100%|██████████| 323/323 [01:43<00:00,  3.13it/s]\n",
      "100%|██████████| 323/323 [01:40<00:00,  3.20it/s]\n",
      "100%|██████████| 4607/4607 [03:40<00:00, 20.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaP:  0.24234265632368546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [01:37<00:00,  3.30it/s]\n",
      "100%|██████████| 323/323 [01:38<00:00,  3.27it/s]\n",
      "100%|██████████| 323/323 [01:40<00:00,  3.22it/s]\n",
      "100%|██████████| 323/323 [01:49<00:00,  2.94it/s]\n",
      "100%|██████████| 323/323 [01:34<00:00,  3.41it/s]\n",
      "100%|██████████| 323/323 [01:32<00:00,  3.48it/s]\n",
      " 27%|██▋       | 86/323 [00:28<01:19,  2.99it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\repos\\belugas\\notebooks\\bce_cnv.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/repos/belugas/notebooks/bce_cnv.ipynb#ch0000011?line=22'>23</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(logits, labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/repos/belugas/notebooks/bce_cnv.ipynb#ch0000011?line=24'>25</a>\u001b[0m scaler\u001b[39m.\u001b[39mscale(loss)\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/repos/belugas/notebooks/bce_cnv.ipynb#ch0000011?line=25'>26</a>\u001b[0m scaler\u001b[39m.\u001b[39;49mstep(optimizer)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/repos/belugas/notebooks/bce_cnv.ipynb#ch0000011?line=26'>27</a>\u001b[0m scaler\u001b[39m.\u001b[39mupdate()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/repos/belugas/notebooks/bce_cnv.ipynb#ch0000011?line=28'>29</a>\u001b[0m run[\u001b[39m'\u001b[39m\u001b[39mrunning/loss\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mlog(loss)\n",
      "File \u001b[1;32mc:\\repos\\belugas\\env\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:338\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[1;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/repos/belugas/env/lib/site-packages/torch/cuda/amp/grad_scaler.py?line=333'>334</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munscale_(optimizer)\n\u001b[0;32m    <a href='file:///c%3A/repos/belugas/env/lib/site-packages/torch/cuda/amp/grad_scaler.py?line=335'>336</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(optimizer_state[\u001b[39m\"\u001b[39m\u001b[39mfound_inf_per_device\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> <a href='file:///c%3A/repos/belugas/env/lib/site-packages/torch/cuda/amp/grad_scaler.py?line=337'>338</a>\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_opt_step(optimizer, optimizer_state, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/repos/belugas/env/lib/site-packages/torch/cuda/amp/grad_scaler.py?line=339'>340</a>\u001b[0m optimizer_state[\u001b[39m\"\u001b[39m\u001b[39mstage\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m OptState\u001b[39m.\u001b[39mSTEPPED\n\u001b[0;32m    <a href='file:///c%3A/repos/belugas/env/lib/site-packages/torch/cuda/amp/grad_scaler.py?line=341'>342</a>\u001b[0m \u001b[39mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32mc:\\repos\\belugas\\env\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:284\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/repos/belugas/env/lib/site-packages/torch/cuda/amp/grad_scaler.py?line=281'>282</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_maybe_opt_step\u001b[39m(\u001b[39mself\u001b[39m, optimizer, optimizer_state, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    <a href='file:///c%3A/repos/belugas/env/lib/site-packages/torch/cuda/amp/grad_scaler.py?line=282'>283</a>\u001b[0m     retval \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/repos/belugas/env/lib/site-packages/torch/cuda/amp/grad_scaler.py?line=283'>284</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39msum\u001b[39;49m(v\u001b[39m.\u001b[39;49mitem() \u001b[39mfor\u001b[39;49;00m v \u001b[39min\u001b[39;49;00m optimizer_state[\u001b[39m\"\u001b[39;49m\u001b[39mfound_inf_per_device\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues()):\n\u001b[0;32m    <a href='file:///c%3A/repos/belugas/env/lib/site-packages/torch/cuda/amp/grad_scaler.py?line=284'>285</a>\u001b[0m         retval \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39mstep(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/repos/belugas/env/lib/site-packages/torch/cuda/amp/grad_scaler.py?line=285'>286</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32mc:\\repos\\belugas\\env\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:284\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/repos/belugas/env/lib/site-packages/torch/cuda/amp/grad_scaler.py?line=281'>282</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_maybe_opt_step\u001b[39m(\u001b[39mself\u001b[39m, optimizer, optimizer_state, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    <a href='file:///c%3A/repos/belugas/env/lib/site-packages/torch/cuda/amp/grad_scaler.py?line=282'>283</a>\u001b[0m     retval \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/repos/belugas/env/lib/site-packages/torch/cuda/amp/grad_scaler.py?line=283'>284</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39msum\u001b[39m(v\u001b[39m.\u001b[39;49mitem() \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m optimizer_state[\u001b[39m\"\u001b[39m\u001b[39mfound_inf_per_device\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    <a href='file:///c%3A/repos/belugas/env/lib/site-packages/torch/cuda/amp/grad_scaler.py?line=284'>285</a>\u001b[0m         retval \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39mstep(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/repos/belugas/env/lib/site-packages/torch/cuda/amp/grad_scaler.py?line=285'>286</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m retval\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    epoch_loss, epoch_acc = 0, 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for anchor, pos, neg in tqdm(train_train_dataloader):\n",
    "\n",
    "        optimizer.zero_grad(True)\n",
    "        \n",
    "        anchor = anchor.to(device, non_blocking=True, dtype=input_dtype)\n",
    "        pos = pos.to(device, non_blocking=True, dtype=input_dtype)\n",
    "        neg = neg.to(device, non_blocking=True, dtype=input_dtype)\n",
    "        \n",
    "        query = torch.cat([anchor, anchor], dim=0)\n",
    "        reference = torch.cat([pos, neg], dim=0)\n",
    "        labels = torch.cat([torch.ones(pos.shape[0],1), torch.zeros(neg.shape[0],1)], dim=0).to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=fp16):\n",
    "            logits = model(query=query, reference=reference)\n",
    "            loss = loss_fn(logits, labels)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        run['running/loss'].log(loss)\n",
    "        \n",
    "        # accuracy\n",
    "        preds = torch.nn.Sigmoid()(logits).round().detach().cpu().numpy()\n",
    "        acc = accuracy_score(labels.detach().cpu().numpy(), preds)\n",
    "        run['running/acc'].log(acc)\n",
    "        \n",
    "        epoch_loss += loss\n",
    "        epoch_acc += acc\n",
    "        \n",
    "    run['epoch/train/loss'].log(epoch_loss / len(train_train_dataloader))\n",
    "    run['epoch/train/acc'].log(epoch_acc / len(train_train_dataloader))\n",
    "    \n",
    "    if epoch_i % 10 == 0:\n",
    "        map = map_score(valid_eval_dataloader, model)\n",
    "        run['epoch5/valid/map'].log(map)\n",
    "        \n",
    "    torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, f'../artifacts/net_{epoch_i}.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, f'../artifacts/net_{epoch_i}_83acc.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal batch size for inference\n",
    "\"\"\"\n",
    "5vcpus\n",
    "52 ram\n",
    "12 ram gpu\n",
    "\n",
    "model to eval, optim bactch size calculate with tqdm\n",
    "\"\"\"\n",
    "model.eval()\n",
    "\n",
    "TEST_INFER_BS_INIT = 10\n",
    "TEST_INFER_BS_ML = 10\n",
    "\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "class DummyTest(torch.utils.data.Dataset):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "  def __len__(self):\n",
    "    return 7000000\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return torch.zeros((3,224,224)), torch.zeros((3,224,224))\n",
    "\n",
    "BS = TEST_INFER_BS_INIT = 5\n",
    "while True:\n",
    "  i = 0\n",
    "  BS = BS + TEST_INFER_BS_ML\n",
    "  dataloader = torch.utils.data.DataLoader(\n",
    "                          DummyTest(), \n",
    "                          batch_size=BS,\n",
    "                          shuffle=False, \n",
    "                          num_workers=0,\n",
    "                          pin_memory=True\n",
    "                      )   \n",
    "\n",
    "  for batch in tqdm(dataloader, total=len(dataloader)):\n",
    "    query = batch[0].to(device, non_blocking=True, dtype=torch.float32)\n",
    "    reference = batch[1].to(device, non_blocking=True, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "      logits, attn, q_cls, r_cls = model(query=query, reference=reference)\n",
    "      i+=1\n",
    "    \n",
    "    if i == 50:\n",
    "      print(BS)\n",
    "      print(torch.cuda.mem_get_info(device=0))\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6465060864, 8589737984)\n"
     ]
    }
   ],
   "source": [
    "fp16 = True \n",
    "input_dtype = torch.float16 if fp16 else torch.float32\n",
    "\n",
    "scaler =  torch.cuda.amp.GradScaler(enabled=fp16)\n",
    "\n",
    "model = crossvit_base_224().to(device)\n",
    "input = torch.zeros((2,3,224,224), dtype=input_dtype, device=device)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "labels = torch.ones((2,1), dtype=input_dtype, device=device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 5e-4)\n",
    "\n",
    "warmup, reps = 30, 10\n",
    "\n",
    "for i in range(0, warmup):\n",
    "    \n",
    "        with torch.cuda.amp.autocast(enabled = fp16):\n",
    "            logits, attn, q_cls, r_cls = model(query=input, reference=input)\n",
    "            loss = loss_fn(logits, labels)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "    profile_memory=True,\n",
    ") as prof:\n",
    "    print(torch.cuda.mem_get_info(0))\n",
    "    for i in range(0, reps):\n",
    "        \n",
    "        with torch.cuda.amp.autocast(enabled = fp16):\n",
    "            \n",
    "            logits, attn, q_cls, r_cls = model(query=input, reference=input)\n",
    "            loss = loss_fn(logits, labels)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          aten::reshape         5.00%     566.319ms        11.90%        1.346s     153.356us     544.024ms         4.84%        1.311s     149.324us           0 b           0 b     542.46 Mb           0 b          8780  \n",
      "                                            aten::copy_         4.72%     534.034ms         4.72%     534.034ms      78.650us     525.057ms         4.67%     525.057ms      77.328us           0 b           0 b           0 b           0 b          6790  \n",
      "                                         aten::_to_copy         4.56%     516.087ms        10.33%        1.170s     227.134us     503.597ms         4.48%        1.151s     223.463us           0 b           0 b       2.03 Gb           0 b          5150  \n",
      "                                       aten::as_strided         4.20%     475.203ms         4.20%     475.203ms      29.297us     453.851ms         4.04%     453.851ms      27.981us           0 b           0 b           0 b           0 b         16220  \n",
      "                                               aten::mm         4.04%     457.166ms         4.04%     457.166ms     155.499us     510.154ms         4.54%     510.154ms     173.522us           0 b           0 b       1.28 Gb       1.28 Gb          2940  \n",
      "                                          aten::permute         3.78%     427.307ms         5.55%     628.754ms      92.737us     439.648ms         3.91%     627.262ms      92.517us           0 b           0 b           0 b           0 b          6780  \n",
      "                                            aten::empty         3.60%     407.873ms         3.60%     407.873ms      74.159us     403.471ms         3.59%     403.471ms      73.358us           0 b           0 b       1.35 Gb       1.35 Gb          5500  \n",
      "                                        aten::transpose         3.07%     347.453ms         4.57%     517.742ms      87.902us     344.904ms         3.07%     519.313ms      88.169us           0 b           0 b           0 b           0 b          5890  \n",
      "                                    aten::empty_strided         2.93%     331.262ms         2.93%     331.262ms      50.420us     331.970ms         2.96%     331.970ms      50.528us           0 b           0 b       2.72 Gb       2.72 Gb          6570  \n",
      "                                                aten::t         2.80%     316.616ms         6.63%     750.914ms     152.315us     320.957ms         2.86%     755.833ms     153.313us           0 b           0 b           0 b           0 b          4930  \n",
      "                                   aten::_reshape_alias         2.50%     283.267ms         2.50%     283.267ms      37.469us     283.366ms         2.52%     283.366ms      37.482us           0 b           0 b           0 b           0 b          7560  \n",
      "                                               aten::to         2.50%     282.847ms        12.83%        1.453s     280.964us     295.169ms         2.63%        1.446s     279.691us           0 b           0 b       2.03 Gb           0 b          5170  \n",
      "                                             aten::add_         2.13%     240.690ms         2.13%     240.690ms      81.590us     244.176ms         2.17%     244.176ms      82.772us           0 b           0 b           0 b           0 b          2950  \n",
      "                                           aten::linear         2.09%     236.620ms        19.31%        2.186s       1.104ms     238.288ms         2.12%        2.180s       1.101ms           0 b           0 b       1.57 Gb           0 b          1980  \n",
      "                                              aten::bmm         2.00%     226.344ms         2.87%     324.686ms     193.265us     220.517ms         1.96%     317.646ms     189.075us           0 b           0 b     852.90 Mb     642.09 Mb          1680  \n",
      "                                       aten::empty_like         1.98%     223.804ms         4.65%     526.345ms     147.024us     220.125ms         1.96%     521.439ms     145.653us           0 b           0 b       1.79 Gb           0 b          3580  \n",
      "autograd::engine::evaluate_function: PermuteBackward...         1.94%     219.509ms         6.43%     727.753ms     215.312us     220.368ms         1.96%     725.153ms     214.542us           0 b           0 b           0 b           0 b          3380  \n",
      "                                           aten::einsum         1.77%     200.538ms         9.10%        1.030s       2.147ms     224.760ms         2.00%        1.032s       2.150ms           0 b           0 b     652.13 Mb           0 b           480  \n",
      "autograd::engine::evaluate_function: ToCopyBackward0...         1.77%     200.472ms         9.14%        1.034s     438.266us     193.696ms         1.72%        1.032s     437.249us           0 b           0 b     725.12 Mb    -703.96 Mb          2360  \n",
      "                                       PermuteBackward0         1.73%     195.666ms         4.49%     508.244ms     150.368us     188.534ms         1.68%     504.785ms     149.345us           0 b           0 b           0 b           0 b          3380  \n",
      "                 struct torch::autograd::AccumulateGrad         1.70%     192.112ms         3.38%     382.221ms     159.259us     187.491ms         1.67%     381.166ms     158.819us           0 b           0 b    -973.02 Mb    -973.02 Mb          2400  \n",
      "                                             aten::view         1.64%     185.266ms         1.64%     185.266ms      33.624us     184.722ms         1.64%     184.722ms      33.525us           0 b           0 b           0 b           0 b          5510  \n",
      "                                            MmBackward0         1.63%     184.982ms         8.02%     907.421ms     925.940us     187.506ms         1.67%     942.223ms     961.452us           0 b           0 b     746.62 Mb           0 b           980  \n",
      "autograd::engine::evaluate_function: ReshapeAliasBac...         1.36%     154.437ms         5.63%     636.799ms     289.454us     153.435ms         1.37%     635.240ms     288.745us           0 b           0 b           0 b    -161.60 Mb          2200  \n",
      "autograd::engine::evaluate_function: struct torch::a...         1.32%     149.725ms         4.70%     531.946ms     221.644us     140.895ms         1.25%     522.061ms     217.525us           0 b           0 b    -973.02 Mb           0 b          2400  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 11.319s\n",
      "Self CUDA time total: 11.233s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages(group_by_stack_n=5).table(sort_by='self_cpu_time_total', row_limit=25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 1, 197])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layers x bs x (q,ref) x cross_attn_depth x n_heads x 1 x tokens(inc cls)\n",
    "attn[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 1, 197])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(attn))\n",
    "print(len(attn[0]))\n",
    "print(len(attn[0][0]))\n",
    "attn[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e460829be586a745d810aec71d83684bd38b76dd3b8d2db700ccf14d30953fce"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
